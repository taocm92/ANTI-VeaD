#Data task treatment:
#This script use data of the ANTI-Vea, as generated by E-Prime 2.0, to provide five tables for task analyses of ANTI (RT and ACC), EV, AV, and ID trials, and one table with all the task indexes

######Install and/or load packages######

if(!require(pacman)){install.packages("pacman")} # Install the package in case it was not installed
library(pacman) #This package ("pacman") serves to install and load other packages simultaneously
p_load(readxl, rockchalk, plyr, Hmisc, tidyverse) #Installing and loading the rest of the packages

##### Set data filters #####

filterRTmin = 200 #To exclude responses below 200 ms
filterRTmax = 1500 #To exclude responses above 1500 ms
experimentalblocks = c(1:6) #To exclude data from practice blocks

##### Load data file (excel format!) #####

data_raw = read_excel("./Inputs/Data_ANTI-VeaD.xlsx", sheet = "Raw_Data") # Search from the PROJECT's working directory (the dot)
data_processed = data_raw %>% #data_processed will be the base where the relevant task indexes are included
  distinct(Subject) #Numbers with no repetition, only taking into account, the $Subject column

#####Identify outliers participants######

#Outliers participants#

  #General task: Participants with more than 25% errors in ANTI trials

x = data_raw %>%
  filter (BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="NoVigilancia") %>% 
  group_by(Subject) %>% #This makes summaries to conduct descriptives at the subject level
  summarise(Target.Error=mean(Target.Error))
outliers_performance = x %>% #This object represents the subjects that have been excluded
  filter (Target.Error > .25) %>% 
  select(Subject) %>% 
  pull() # Make the output a value (single vector), and not a structure of data
n_excluded_bcperformance = length(outliers_performance) # This object is the number of subjects that have been excluded

x = x %>% 
  transmute(Validity_GeneralTask=ifelse(Target.Error > .25, "No","Yes"))
data_processed = cbind(data_processed,x)
data_processed$Validity_GeneralTask = as.factor(data_processed$Validity_GeneralTask)

  #Irrelevant distractor trials# Participants with more than 25% errors in distractor present condition

x = data_raw %>% 
  filter (BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="DP") %>% 
  group_by(Subject) %>% 
  summarise(Target.Error=mean(Target.Error))
outliers_performance_IDtrials = x %>% #This object represents the subjects that have been excluded
  filter(Target.Error > .25) %>% 
  select(Subject) %>% 
  pull()
n_excluded_bcperformance_IDtrials = length(outliers_performance_IDtrials) # This object is the number of subjects that have been excluded

x = x %>% 
  transmute(Validity_IDtrials=ifelse(Target.Error > .25, "No","Yes"))
data_processed = cbind(data_processed,x)
data_processed$Validity_IDtrials = as.factor(data_processed$Validity_IDtrials)

rm(x)

#####Identify outliers trials######

  #ANTI RT#

x = data_raw %>% 
  filter(!Subject %in% outliers_performance) %>%
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="NoVigilancia")
filterRT_percentage_errors = round(100*(as.numeric(x %>% tally(Target.ACC==0))/as.numeric(x %>% tally(Target.ACC %in% c(0,1)))),digits = 4) # Percentage of incorrect trials (outlier subjects excluded)
filterRT_percentage_time = round(100*(as.numeric(x %>% tally(Target.RT<filterRTmin))+as.numeric(x %>% tally(Target.RT>filterRTmax)))/as.numeric(x %>% tally(!Target.RT<0)),digits = 4) # Percentage of trials excluded after RT filter (outlier subjects excluded)
rm(x)

  #ID RT#

x = data_raw %>% 
  filter(!Subject %in% c(outliers_performance, outliers_performance_IDtrials)) %>%
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="DP")
filterRT_percentage_errors_ID = round(100*(as.numeric(x %>% tally(Target.ACC==0))/as.numeric(x %>% tally(Target.ACC %in% c(0,1)))),digits = 4) # Percentage of incorrect trials (outlier subjects excluded)
filterRT_percentage_time_ID = round(100*(as.numeric(x %>% tally(Target.RT<filterRTmin))+as.numeric(x %>% tally(Target.RT>filterRTmax)))/as.numeric(x %>% tally(!Target.RT<0)),digits = 4) # Percentage of trials excluded after RT filter (outlier subjects excluded)
rm(x)

#### ANTI Trials ####

# RT analysis of ANTI trials #

# Select appropriate trials (Only experimental blocks, ANTI trials, drop errors, filter RT) #

data_rt = data_raw %>% 
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="NoVigilancia", Target.ACC==1, Target.RT>filterRTmin, Target.RT<filterRTmax)
  
# Generate data table for RT analyses #

data_rt_table = data_rt %>% # Table with the relevant outcomes for task check
  group_by(Subject, `Tono[Trial]`, `ValidezClave[Trial]`, `Congruency[Trial]`) %>% 
  summarise(Target.RT=mean(Target.RT)) %>% 
  mutate(Condition = paste(`Tono[Trial]`,`ValidezClave[Trial]`,`Congruency[Trial]`, sep = "_"))
data_rt_table = as.data.frame(data_rt_table) %>% 
  reshape(idvar = "Subject", timevar = "Condition", drop = c("Tono[Trial]", "ValidezClave[Trial]", "Congruency[Trial]"), direction = "wide")

# Compute attentional scores #

#Overall

x = as.data.frame(data_rt) %>% 
  group_by(Subject) %>% 
  summarise(Overall_RT=mean(Target.RT))
data_processed=bind_cols(data_processed,x[2])

#Alerting
x = as.data.frame(data_rt) %>% 
  group_by(Subject, `Tono[Trial]`) %>% 
  summarise(Target.RT=mean(Target.RT)) %>%  
  spread(`Tono[Trial]`, Target.RT) %>% 
  mutate(Alerting_RT = notono - tono) %>%
  rename(notono_RT=notono,tono_RT=tono) 
data_rt_table=bind_cols(data_rt_table,x[2:3])
data_processed=bind_cols(data_processed,x[4])

#Orienting
x = as.data.frame(data_rt) %>% 
  group_by(Subject, `ValidezClave[Trial]`) %>% 
  summarise(Target.RT=mean(Target.RT)) %>%  
  spread(`ValidezClave[Trial]`, Target.RT) %>% 
  mutate(Orienting_RT = invalida - valida) %>%
  rename(invalid_RT=invalida,nocue_RT=nocue,valid_RT=valida)
data_rt_table=bind_cols(data_rt_table,x[2:4])
data_processed=bind_cols(data_processed,x[5])

#Congruency
x = as.data.frame(data_rt) %>% 
  group_by(Subject, `Congruency[Trial]`) %>% 
  summarise(Target.RT=mean(Target.RT)) %>%  
  spread(`Congruency[Trial]`, Target.RT) %>% 
  mutate(Congruency_RT = incongruent - congruent) %>%
  rename(incongruent_RT=incongruent,congruent_RT=congruent)
data_rt_table=bind_cols(data_rt_table,x[2:3])
data_processed=bind_cols(data_processed,x[4])

rm(x)

data_rt_table = data_rt_table %>% #Removing outliers from task analyses of ANTI RT trials
  filter(!Subject %in% outliers_performance)

# ACC analysis of ANTI trials #

# Select appropriate trials (Only experimental blocks and ANTI trials) #

data_acc = data_raw %>% 
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="NoVigilancia")

# Generate data table for ACC (percentage errors) analysis #

data_acc_table = data_acc %>% # Table with the relevant outcomes for task check
  group_by(Subject, `Tono[Trial]`, `ValidezClave[Trial]`, `Congruency[Trial]`) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%
  mutate(Condition = paste(`Tono[Trial]`,`ValidezClave[Trial]`,`Congruency[Trial]`, sep = "_"))
data_acc_table = as.data.frame(data_acc_table) %>%
  reshape(idvar = "Subject", timevar = "Condition", drop = c("Tono[Trial]", "ValidezClave[Trial]", "Congruency[Trial]"), direction = "wide")

# Compute attentional scores #

#Overall
x = as.data.frame(data_acc) %>% 
  group_by(Subject) %>% 
  summarise(Overall_ACC=(1-mean(Target.ACC))*100)
data_processed=bind_cols(data_processed,x[2])

#Alerting
x = as.data.frame(data_acc) %>% 
  group_by(Subject, `Tono[Trial]`) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%  
  spread(`Tono[Trial]`, Target.ACC) %>% 
  mutate(Alerting_ACC = notono - tono) %>%
  rename(notono_ACC=notono,tono_ACC=tono)
data_acc_table=bind_cols(data_acc_table,x[2:3])
data_processed=bind_cols(data_processed,x[4])

#Orienting
x = as.data.frame(data_acc) %>% 
  group_by(Subject, `ValidezClave[Trial]`) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%  
  spread(`ValidezClave[Trial]`, Target.ACC) %>% 
  mutate(Orienting_ACC = invalida - valida) %>%
  rename(invalid_ACC=invalida,nocue_ACC=nocue,valid_ACC=valida)
data_acc_table=bind_cols(data_acc_table,x[2:4])
data_processed=bind_cols(data_processed,x[5])

#Congruency
x = as.data.frame(data_acc) %>% 
  group_by(Subject, `Congruency[Trial]`) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%  
  spread(`Congruency[Trial]`, Target.ACC) %>% 
  mutate(Congruency_ACC = incongruent - congruent) %>%
  rename(incongruent_ACC=incongruent,congruent_ACC=congruent)
data_acc_table=bind_cols(data_acc_table,x[2:3])
data_processed=bind_cols(data_processed,x[4])

rm(x)

data_acc_table = data_acc_table %>% #Removing outliers from task analyses of ANTI percentage errors trials
  filter(!Subject %in% outliers_performance)
  
#### EV Trials ####

# Select appropriate trials (NOT drop first block) #

data_EV = data_raw %>% 
  filter(BlockList %in% experimentalblocks)
data_EV_table = data_EV %>% # Executive Vigilance scores per block for performance over time analyses
  distinct(Subject)

# Define functions for A' and B''#

Aprime = function(Hits_Percentage, FA_Percentage)
{
  ifelse(Hits_Percentage/100 < FA_Percentage/100 | Hits_Percentage/100 == 0,
         0.5,
         0.5 + (((Hits_Percentage/100 - FA_Percentage/100)*(1 + Hits_Percentage/100 - FA_Percentage/100)) / (4*(Hits_Percentage/100)*(1 - (FA_Percentage/100)))))
}

Bprime = function(Hits_Percentage, FA_Percentage)
{
  ifelse(Hits_Percentage/100==0 & FA_Percentage/100==0,
         1,
         ifelse(Hits_Percentage/100==1,
                -1,
                (((Hits_Percentage/100) * (1 - Hits_Percentage/100)) - ((FA_Percentage/100) * (1 - FA_Percentage/100))) / (((Hits_Percentage/100) * (1 - Hits_Percentage/100)) + ((FA_Percentage/100) * (1 - (FA_Percentage/100)))))) 
}

# Compute EV scores #

#Hits (percentage)
x = data_EV %>% 
  filter(`Vigilancia[Trial]` =="VE") %>% 
  group_by(Subject) %>% 
  summarise(Hits_Percentage=mean(Target.ACC)*100)
data_processed=bind_cols(data_processed,x[2])

#False Alarms (percentage)  
x = data_EV %>% 
  filter(Trial_FA_Difficult =="YES") %>% 
  group_by(Subject) %>% 
  summarise(FA_Percentage=mean(FA_Difficult)*100) 
data_processed=bind_cols(data_processed,x[2])

#A' (sensitivity)
data_processed = data_processed %>%
  mutate(Ap=Aprime(Hits_Percentage,FA_Percentage))

#B'' (response bias)
data_processed = data_processed %>%
  mutate(Bp=Bprime(Hits_Percentage,FA_Percentage))

rm(x)

#Calculating EV Slopes#

#Hits slope
x = data_EV %>% 
  filter(`Vigilancia[Trial]` =="VE") %>% 
  group_by(Subject,BlockList) %>% 
  summarise(Hits_Percentage=mean(Target.ACC)*100) %>% 
  spread(BlockList,Hits_Percentage) %>% 
  mutate(Hits_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("EV_Hits_B", x)})
data_EV_table=bind_cols(data_EV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])

#False alarms slope
x = data_EV %>% 
  filter(Trial_FA_Difficult =="YES") %>% 
  group_by(Subject,BlockList) %>% 
  summarise(FA_Percentage=mean(FA_Difficult)*100) %>% 
  spread(BlockList,FA_Percentage) %>% 
  mutate(FA_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("EV_FA_B", x)})
data_EV_table=bind_cols(data_EV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])

#A' (sensitivity) slope
x = data_EV %>% 
  group_by(Subject,BlockList) %>% 
  summarise(Hits_Percentage=mean(Target.ACC[which(`Vigilancia[Trial]` =="VE")])*100, FA_Percentage=mean(FA_Difficult[which(Trial_FA_Difficult=="YES")])*100) %>% 
  mutate(Ap=Aprime(Hits_Percentage,FA_Percentage)) %>% 
  select(-Hits_Percentage,-FA_Percentage) %>% 
  spread(BlockList,Ap) %>% 
  mutate(Ap_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("EV_Ap_B", x)})
data_EV_table=bind_cols(data_EV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])

#B'' (response bias) slope
x = data_EV %>% 
  group_by(Subject,BlockList) %>% 
  summarise(Hits_Percentage=mean(Target.ACC[which(`Vigilancia[Trial]` =="VE")])*100, FA_Percentage=mean(FA_Difficult[which(Trial_FA_Difficult=="YES")])*100) %>% 
  mutate(Bp=Bprime(Hits_Percentage,FA_Percentage)) %>% 
  select(-Hits_Percentage,-FA_Percentage) %>% 
  spread(BlockList,Bp) %>% 
  mutate(Bp_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("EV_Bp_B", x)})
data_EV_table=bind_cols(data_EV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])

rm(x)

data_EV_table = data_EV_table %>% #Removing outliers from task analyses of EV performance over time
  filter(!Subject %in% outliers_performance)

#### AV Trials ####

# Select appropriate trials (NOT drop first block) #

data_AV = data_raw %>% 
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]` =="VA")
data_AV_table = data_AV %>% # Arousal Vigilance scores per block for performance over time analyses
  distinct(Subject)

# Compute AV scores #

#Mean

x = as.data.frame(data_AV) %>% 
  group_by(Subject) %>% 
  summarise(AV_Mean=mean(TargetVA.RT))
data_processed=bind_cols(data_processed,x[2])

#SD
x = as.data.frame(data_AV) %>% 
  group_by(Subject) %>% 
  summarise(AV_SD=sd(TargetVA.RT))
data_processed=bind_cols(data_processed,x[2])

#Percentage lapses

x = as.data.frame(data_AV) %>% 
  group_by(Subject) %>% 
  summarise(AV_Lapses=mean(Lapsus_Juan)*100)
data_processed=bind_cols(data_processed,x[2])

rm(x)

#Calculate AV slopes#

#Mean slope

x = data_AV %>% 
  group_by(Subject,BlockList) %>% 
  summarise(AV_Mean=mean(TargetVA.RT)) %>% 
  spread(BlockList,AV_Mean) %>% 
  mutate(AV_Mean_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("AV_Mean_B", x)})
data_AV_table=bind_cols(data_AV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])

#SD

x = data_AV %>% 
  group_by(Subject,BlockList) %>% 
  summarise(AV_SD=sd(TargetVA.RT)) %>% 
  spread(BlockList,AV_SD) %>% 
  mutate(AV_SD_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("AV_SD_B", x)})
data_AV_table=bind_cols(data_AV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])

#Lapses

x = data_AV %>% 
  group_by(Subject,BlockList) %>% 
  summarise(AV_Lapses=mean(Lapsus_Juan)) %>% 
  spread(BlockList,AV_Lapses) %>% 
  mutate(AV_Lapses_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("AV_Lapses_B", x)})
data_AV_table=bind_cols(data_AV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])

rm(x)

data_AV_table = data_AV_table %>% #Removing outliers from task analyses of AV performance over time
  filter(!Subject %in% outliers_performance)

####ID trials####

IDtrials = c("DP", "DA")# Define IDtrials as the combination of distractor-present(DP) and distractor-absent(DA) trials

# RT analysis of ID trials #

# Select appropriate trials (Only experimental blocks, ID trials, drop errors, filter RT) #

data_ID_rt = data_raw %>% 
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]` %in% IDtrials, Target.ACC==1, Target.RT<filterRTmax, Target.RT>filterRTmin)

# Generate data table for ID analyses #

data_ID_table = data_ID_rt %>% # Table with the relevant outcomes for task check
  group_by(Subject, `Vigilancia[Trial]`) %>% 
  summarise(Target.RT=mean(Target.RT)) %>%
  spread(`Vigilancia[Trial]`,Target.RT) %>% 
  rename_at(vars(DA:DP) ,function(x){paste0(x,"_RT")})

x = data_ID_rt %>% # Exploratory analysis of distractor position (same or opposite side as the target)
  group_by(Subject, LugarDistractortoTarget) %>% 
  summarise(Target.RT=mean(Target.RT)) %>%
  spread(LugarDistractortoTarget,Target.RT) %>% 
  rename_at(vars(opposite:same) ,function(x){paste0("Exploratory_D",x,"_RT")})
data_ID_table = bind_cols(data_ID_table,x[3:4])

rm(x)

# Compute ID analysis for RT (z-scores) #

#Interference of ID (RT)

x = data_ID_table %>%
  mutate(ID_zRT = (DP_RT-DA_RT)/DA_RT)
data_processed=bind_cols(data_processed,x[6])

#Exploratory: Interference of ID (RT) considering when distractor is presented in the same and the opposite side as the target location

x = data_ID_table %>%
  mutate(Exploratory_ID_zRTsame = (Exploratory_Dsame_RT-DA_RT)/DA_RT) %>% 
  mutate(Exploratory_ID_zRTopposite = (Exploratory_Dopposite_RT-DA_RT)/DA_RT) 
data_processed=bind_cols(data_processed,x[6:7])

rm(x)

# ACC analysis (percentage errors) of ID trials #

# Select appropriate trials (Only experimental blocks and ID trials) #

data_ID_acc = data_raw %>% 
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]` %in% IDtrials)

# Complete data table for ID analyses #

x = data_ID_acc %>% # Table with the relevant outcomes for task check
  group_by(Subject, `Vigilancia[Trial]`) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%
  spread(`Vigilancia[Trial]`,Target.ACC) %>% 
  rename_at(vars(DA:DP) ,function(x){paste0(x,"_PercentageErrors")})
data_ID_table = bind_cols(data_ID_table,x[2:3])

x = data_ID_acc %>% # Exploratory analysis of distractor position (same or opposite side as the target)
  group_by(Subject, LugarDistractortoTarget) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%
  spread(LugarDistractortoTarget,Target.ACC) %>% 
  rename_at(vars(opposite:same) ,function(x){paste0("Exploratory_D",x,"_PercentageErrors")})
data_ID_table = bind_cols(data_ID_table,x[3:4])

rm(x)

# Compute ID analysis for percentage errors (raw difference scores) #

#Errors interference from ID

x = data_ID_table %>%
  mutate(ID_PercentageErrors = DP_PercentageErrors - DA_PercentageErrors)
data_processed=bind_cols(data_processed,x["ID_PercentageErrors"])

#Exploratory: Errors interference from ID considering when distractor is presented in the same and the opposite side as the target location

x = data_ID_table %>%
  mutate(Exploratory_PercentageErrorssame = Exploratory_Dsame_PercentageErrors - DA_PercentageErrors) %>% 
  mutate(Exploratory_PercentageErrorsopposite = Exploratory_Dopposite_PercentageErrors - DA_PercentageErrors)
data_processed=bind_cols(data_processed,x[c("Exploratory_PercentageErrorssame","Exploratory_PercentageErrorsopposite")])

rm(x)

data_ID_table = data_ID_table %>% #Removing outliers from task analyses of ID trials
  filter(!Subject %in% c(outliers_performance,outliers_performance_IDtrials))

####Export tables####

# Export tables of task analysis #

write.table(data_rt_table, "./Outputs/From_DataTaskTreatment/data_rt_table.csv", sep =",", row.names = FALSE)
write.table(data_acc_table, "./Outputs/From_DataTaskTreatment/data_acc_table.csv", sep =",", row.names = FALSE)
write.table(data_EV_table, "./Outputs/From_DataTaskTreatment/data_EV_table.csv", sep =",", row.names = FALSE)
write.table(data_AV_table, "./Outputs/From_DataTaskTreatment/data_AV_table.csv", sep =",", row.names = FALSE)
write.table(data_ID_table, "./Outputs/From_DataTaskTreatment/data_ID_table.csv", sep =",", row.names = FALSE)

# Export tables of task indexes # Use this file in combination with self-report scores

write.table(data_processed, "./Outputs/From_DataTaskTreatment/data_processed.csv", sep =",", row.names = FALSE)

