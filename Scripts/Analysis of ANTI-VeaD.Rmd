---
title: "ANTI-VeaD: Data treatment and analyses"
author: "Tao Coll-MartÃ­n"
date: "7/9/2020" 
output: 
  html_document:
    theme: readable
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

This script use data of the ANTI-Vea, as generated by E-Prime 2.0, to provide five tables for task analyses of ANTI (RT and ACC), EV, AV, and ID trials, and one table with all the task indexes.

# Install and/or load packages

```{r}
if(!require(pacman)){install.packages("pacman")} # Install the package in case it was not installed

library(pacman) #This package ("pacman") serves to install and load other packages simultaneously

p_load(readxl, rockchalk, plyr, Hmisc, tidyverse) #Install and load the rest of the packages
```

# Set data filters

```{r}
filterRTmin = 200 #To exclude responses below 200 ms
filterRTmax = 1500 #To exclude responses above 1500 ms
experimentalblocks = c(1:6) #To exclude data from practice blocks
```


# Load data file (excel format!)

```{r}
data_raw = read_excel("./Inputs/Data_ANTI-VeaD.xlsx", sheet = "Raw_Data") # Search from the PROJECT's working directory (the dot)
data_processed = data_raw %>% #data_processed will be the base where the relevant task indexes are included
  distinct(Subject) #Numbers with no repetition, only taking into account, the $Subject column
```


# Identify outliers

## Outliers participants

### General task: Participants with more than 25% errors in ANTI trials

```{r}
x = data_raw %>%
  filter (BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="NoVigilancia") %>% 
  group_by(Subject) %>% #This makes summaries to conduct descriptives at the subject level
  summarise(Target.Error=mean(Target.Error))
outliers_performance = x %>% #This object represents the subjects that have been excluded
  filter (Target.Error > .25) %>% 
  select(Subject) %>% 
  pull() # Make the output a value (single vector), and not a structure of data
n_excluded_bcperformance = length(outliers_performance) # This object is the number of subjects that have been excluded

x = x %>% 
  transmute(Validity_GeneralTask=ifelse(Target.Error > .25, "No","Yes"))
data_processed = cbind(data_processed,x)
data_processed$Validity_GeneralTask = as.factor(data_processed$Validity_GeneralTask)
```

### Irrelevant distractor trials: Participants with more than 25% errors in distractor present condition

```{r}
x = data_raw %>% 
  filter (BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="DP") %>% 
  group_by(Subject) %>% 
  summarise(Target.Error=mean(Target.Error))
outliers_performance_IDtrials = x %>% #This object represents the subjects that have been excluded
  filter(Target.Error > .25) %>% 
  select(Subject) %>% 
  pull()
n_excluded_bcperformance_IDtrials = length(outliers_performance_IDtrials) # This object is the number of subjects that have been excluded

x = x %>% 
  transmute(Validity_IDtrials=ifelse(Target.Error > .25, "No","Yes"))
data_processed = cbind(data_processed,x)
data_processed$Validity_IDtrials = as.factor(data_processed$Validity_IDtrials)

rm(x)
```

## Outliers trials

### ANTI RT

```{r}
x = data_raw %>% 
  filter(!Subject %in% outliers_performance) %>%
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="NoVigilancia")
filterRT_percentage_errors = x %>% # Percentage of incorrect trials (outlier subjects excluded)
  summarise(round(100*sum(Target.ACC == 0)/sum(Target.ACC %>% c(0,1)), digits = 4)) %>% 
  pull()
filterRT_percentage_time = x %>% # Percentage of trials excluded after RT filter (outlier subjects excluded)
  summarise(round(100*sum(!(x$Target.RT > (filterRTmin) & x$Target.RT < filterRTmax))/sum(x$Target.RT > (filterRTmin) & x$Target.RT < filterRTmax), digits=4)) %>% 
  pull()
rm(x)
```

### ID RT
```{r}
x = data_raw %>% 
  filter(!Subject %in% c(outliers_performance, outliers_performance_IDtrials)) %>%
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="DP")
filterRT_percentage_errors_ID = x %>% # Percentage of incorrect trials (outlier subjects excluded)
  summarise(round(100*sum(Target.ACC == 0)/sum(Target.ACC %>% c(0,1)), digits = 4)) %>% 
  pull()
filterRT_percentage_time_ID = x %>% # Percentage of trials excluded after RT filter (outlier subjects excluded)
  summarise(round(100*sum(!(x$Target.RT > (filterRTmin) & x$Target.RT < filterRTmax))/sum(x$Target.RT > (filterRTmin) & x$Target.RT < filterRTmax), digits=4)) %>% 
  pull()
rm(x)
```

# ANTI Trials

## RT analysis of ANTI trials

### Select appropriate trials (Only experimental blocks, ANTI trials, drop errors, filter RT)
```{r}
data_rt = data_raw %>% 
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="NoVigilancia", Target.ACC==1, Target.RT>filterRTmin, Target.RT<filterRTmax)
```

### Generate data table for RT analyses
```{r}
data_rt_table = data_rt %>% # Table with the relevant outcomes for task check
  group_by(Subject, `Tono[Trial]`, `ValidezClave[Trial]`, `Congruency[Trial]`) %>% 
  summarise(Target.RT=mean(Target.RT)) %>% 
  mutate(Condition = paste(`Tono[Trial]`,`ValidezClave[Trial]`,`Congruency[Trial]`, sep = "_"))
data_rt_table = as.data.frame(data_rt_table) %>% 
  reshape(idvar = "Subject", timevar = "Condition", drop = c("Tono[Trial]", "ValidezClave[Trial]", "Congruency[Trial]"), direction = "wide")
```

### Compute attentional scores #

#### Overall
```{r}
x = as.data.frame(data_rt) %>% 
  group_by(Subject) %>% 
  summarise(Overall_RT=mean(Target.RT))
data_processed=bind_cols(data_processed,x[2])
```

#### Alerting
```{r}
x = as.data.frame(data_rt) %>% 
  group_by(Subject, `Tono[Trial]`) %>% 
  summarise(Target.RT=mean(Target.RT)) %>%  
  spread(`Tono[Trial]`, Target.RT) %>% 
  mutate(Alerting_RT = notono - tono) %>%
  rename(notono_RT=notono,tono_RT=tono) 
data_rt_table=bind_cols(data_rt_table,x[2:3])
data_processed=bind_cols(data_processed,x[4])
```

#### Orienting
```{r}
x = as.data.frame(data_rt) %>% 
  group_by(Subject, `ValidezClave[Trial]`) %>% 
  summarise(Target.RT=mean(Target.RT)) %>%  
  spread(`ValidezClave[Trial]`, Target.RT) %>% 
  mutate(Orienting_RT = invalida - valida) %>%
  rename(invalid_RT=invalida,nocue_RT=nocue,valid_RT=valida)
data_rt_table=bind_cols(data_rt_table,x[2:4])
data_processed=bind_cols(data_processed,x[5])
```

#### Congruency
```{r}
x = as.data.frame(data_rt) %>% 
  group_by(Subject, `Congruency[Trial]`) %>% 
  summarise(Target.RT=mean(Target.RT)) %>%  
  spread(`Congruency[Trial]`, Target.RT) %>% 
  mutate(Congruency_RT = incongruent - congruent) %>%
  rename(incongruent_RT=incongruent,congruent_RT=congruent)
data_rt_table=bind_cols(data_rt_table,x[2:3])
data_processed=bind_cols(data_processed,x[4])

rm(x)
```

```{r}
data_rt_table = data_rt_table %>% 
  filter(!Subject %in% outliers_performance) #Removing outliers from task analyses of ANTI RT trials
```

## ACC analysis of ANTI trials

### Select appropriate trials (Only experimental blocks and ANTI trials)
```{r}
data_acc = data_raw %>% 
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]`=="NoVigilancia")
```

### Generate data table for ACC (percentage errors) analysis
```{r}
data_acc_table = data_acc %>% # Table with the relevant outcomes for task check
  group_by(Subject, `Tono[Trial]`, `ValidezClave[Trial]`, `Congruency[Trial]`) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%
  mutate(Condition = paste(`Tono[Trial]`,`ValidezClave[Trial]`,`Congruency[Trial]`, sep = "_"))
data_acc_table = as.data.frame(data_acc_table) %>%
  reshape(idvar = "Subject", timevar = "Condition", drop = c("Tono[Trial]", "ValidezClave[Trial]", "Congruency[Trial]"), direction = "wide")
```

### Compute attentional scores

#### Overall
```{r}
x = as.data.frame(data_acc) %>% 
  group_by(Subject) %>% 
  summarise(Overall_ACC=(1-mean(Target.ACC))*100)
data_processed=bind_cols(data_processed,x[2])
```

#### Alerting
```{r}
x = as.data.frame(data_acc) %>% 
  group_by(Subject, `Tono[Trial]`) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%  
  spread(`Tono[Trial]`, Target.ACC) %>% 
  mutate(Alerting_ACC = notono - tono) %>%
  rename(notono_ACC=notono,tono_ACC=tono)
data_acc_table=bind_cols(data_acc_table,x[2:3])
data_processed=bind_cols(data_processed,x[4])
```

#### Orienting
```{r}
x = as.data.frame(data_acc) %>% 
  group_by(Subject, `ValidezClave[Trial]`) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%  
  spread(`ValidezClave[Trial]`, Target.ACC) %>% 
  mutate(Orienting_ACC = invalida - valida) %>%
  rename(invalid_ACC=invalida,nocue_ACC=nocue,valid_ACC=valida)
data_acc_table=bind_cols(data_acc_table,x[2:4])
data_processed=bind_cols(data_processed,x[5])
```

#### Congruency
```{r}
x = as.data.frame(data_acc) %>% 
  group_by(Subject, `Congruency[Trial]`) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%  
  spread(`Congruency[Trial]`, Target.ACC) %>% 
  mutate(Congruency_ACC = incongruent - congruent) %>%
  rename(incongruent_ACC=incongruent,congruent_ACC=congruent)
data_acc_table=bind_cols(data_acc_table,x[2:3])
data_processed=bind_cols(data_processed,x[4])

rm(x)
```

```{r}
data_acc_table = data_acc_table %>% 
  filter(!Subject %in% outliers_performance) #Removing outliers from task analyses of ANTI percentage errors trials
```

# EV Trials

### Select appropriate trials (NOT drop first block)

```{r}
data_EV = data_raw %>% 
  filter(BlockList %in% experimentalblocks)
data_EV_table = data_EV %>% # Executive Vigilance scores per block for performance over time analyses
  distinct(Subject)
```

### Define functions for A' and B''

#### Aprime
```{r}
Aprime = function(Hits_Percentage, FA_Percentage)
{
  ifelse(Hits_Percentage/100 < FA_Percentage/100 | Hits_Percentage/100 == 0,
         0.5,
         0.5 + (((Hits_Percentage/100 - FA_Percentage/100)*(1 + Hits_Percentage/100 - FA_Percentage/100)) / (4*(Hits_Percentage/100)*(1 - (FA_Percentage/100)))))
}
```

#### Bprime
```{r}
Bprime = function(Hits_Percentage, FA_Percentage)
{
  ifelse(Hits_Percentage/100==0 & FA_Percentage/100==0,
         1,
         ifelse(Hits_Percentage/100==1,
                -1,
                (((Hits_Percentage/100) * (1 - Hits_Percentage/100)) - ((FA_Percentage/100) * (1 - FA_Percentage/100))) / (((Hits_Percentage/100) * (1 - Hits_Percentage/100)) + ((FA_Percentage/100) * (1 - (FA_Percentage/100)))))) 
}
```

## Compute EV scores (overall performance)

### Hits (percentage)
```{r}
x = data_EV %>% 
  filter(`Vigilancia[Trial]` =="VE") %>% 
  group_by(Subject) %>% 
  summarise(Hits_Percentage=mean(Target.ACC)*100)
data_processed=bind_cols(data_processed,x[2])
```

### False Alarms (percentage)  
```{r}
x = data_EV %>% 
  filter(Trial_FA_Difficult =="YES") %>% 
  group_by(Subject) %>% 
  summarise(FA_Percentage=mean(FA_Difficult)*100) 
data_processed=bind_cols(data_processed,x[2])
```

### A' (sensitivity)
```{r}
data_processed = data_processed %>%
  mutate(Ap=Aprime(Hits_Percentage,FA_Percentage))
```

### B'' (response bias)
```{r}
data_processed = data_processed %>%
  mutate(Bp=Bprime(Hits_Percentage,FA_Percentage))

rm(x)
```

## Calculating EV Slopes

### Hits slope

```{r}
x = data_EV %>% 
  filter(`Vigilancia[Trial]` =="VE") %>% 
  group_by(Subject,BlockList) %>% 
  summarise(Hits_Percentage=mean(Target.ACC)*100) %>% 
  spread(BlockList,Hits_Percentage) %>% 
  mutate(Hits_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("EV_Hits_B", x)})
data_EV_table=bind_cols(data_EV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])
```

### False alarms slope
```{r}
x = data_EV %>% 
  filter(Trial_FA_Difficult =="YES") %>% 
  group_by(Subject,BlockList) %>% 
  summarise(FA_Percentage=mean(FA_Difficult)*100) %>% 
  spread(BlockList,FA_Percentage) %>% 
  mutate(FA_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("EV_FA_B", x)})
data_EV_table=bind_cols(data_EV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])
```

### A' (sensitivity) slope

```{r}
x = data_EV %>% 
  group_by(Subject,BlockList) %>% 
  summarise(Hits_Percentage=mean(Target.ACC[which(`Vigilancia[Trial]` =="VE")])*100, FA_Percentage=mean(FA_Difficult[which(Trial_FA_Difficult=="YES")])*100) %>% 
  mutate(Ap=Aprime(Hits_Percentage,FA_Percentage)) %>% 
  select(-Hits_Percentage,-FA_Percentage) %>% 
  spread(BlockList,Ap) %>% 
  mutate(Ap_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("EV_Ap_B", x)})
data_EV_table=bind_cols(data_EV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])
```

### B'' (response bias) slope

```{r}
x = data_EV %>% 
  group_by(Subject,BlockList) %>% 
  summarise(Hits_Percentage=mean(Target.ACC[which(`Vigilancia[Trial]` =="VE")])*100, FA_Percentage=mean(FA_Difficult[which(Trial_FA_Difficult=="YES")])*100) %>% 
  mutate(Bp=Bprime(Hits_Percentage,FA_Percentage)) %>% 
  select(-Hits_Percentage,-FA_Percentage) %>% 
  spread(BlockList,Bp) %>% 
  mutate(Bp_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("EV_Bp_B", x)})
data_EV_table=bind_cols(data_EV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])

rm(x)
```

```{r}
data_EV_table = data_EV_table %>% 
  filter(!Subject %in% outliers_performance) #Removing outliers from task analyses of EV performance over time
```

# AV Trials

### Select appropriate trials (NOT drop first block)

```{r}
data_AV = data_raw %>% 
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]` =="VA")
data_AV_table = data_AV %>% # Arousal Vigilance scores per block for performance over time analyses
  distinct(Subject)
```

## Compute AV scores (overall performance)

### Mean

```{r}
x = as.data.frame(data_AV) %>% 
  group_by(Subject) %>% 
  summarise(AV_Mean=mean(TargetVA.RT))
data_processed=bind_cols(data_processed,x[2])
```

### SD
```{r}
x = as.data.frame(data_AV) %>% 
  group_by(Subject) %>% 
  summarise(AV_SD=sd(TargetVA.RT))
data_processed=bind_cols(data_processed,x[2])
```

### Percentage lapses
```{r}
x = as.data.frame(data_AV) %>% 
  group_by(Subject) %>% 
  summarise(AV_Lapses=mean(Lapsus_Juan)*100)
data_processed=bind_cols(data_processed,x[2])

rm(x)
```

## Calculate AV slopes

### Mean slope
```{r}
x = data_AV %>% 
  group_by(Subject,BlockList) %>% 
  summarise(AV_Mean=mean(TargetVA.RT)) %>% 
  spread(BlockList,AV_Mean) %>% 
  mutate(AV_Mean_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("AV_Mean_B", x)})
data_AV_table=bind_cols(data_AV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])
```

### SD
```{r}
x = data_AV %>% 
  group_by(Subject,BlockList) %>% 
  summarise(AV_SD=sd(TargetVA.RT)) %>% 
  spread(BlockList,AV_SD) %>% 
  mutate(AV_SD_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("AV_SD_B", x)})
data_AV_table=bind_cols(data_AV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])
```

### Lapses
```{r}
x = data_AV %>% 
  group_by(Subject,BlockList) %>% 
  summarise(AV_Lapses=mean(Lapsus_Juan)) %>% 
  spread(BlockList,AV_Lapses) %>% 
  mutate(AV_Lapses_Slope = coef(lm(c(`1`,`2`,`3`,`4`,`5`,`6`) ~ experimentalblocks))[2]) %>% 
  rename_at(vars(`1`:`6`) ,function(x){paste0("AV_Lapses_B", x)})
data_AV_table=bind_cols(data_AV_table,x[2:7])
data_processed=bind_cols(data_processed,x[8])

rm(x)
```

```{r}
data_AV_table = data_AV_table %>% 
  filter(!Subject %in% outliers_performance) #Removing outliers from task analyses of AV performance over time
```

# ID trials

```{r}
IDtrials = c("DP", "DA")# Define IDtrials as the combination of distractor-present(DP) and distractor-absent(DA) trials
```

## RT analysis of ID trials

### Select appropriate trials (Only experimental blocks, ID trials, drop errors, filter RT) 
```{r}
data_ID_rt = data_raw %>% 
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]` %in% IDtrials, Target.ACC==1, Target.RT<filterRTmax, Target.RT>filterRTmin)
```

### Generate data table for ID analyses
```{r}
data_ID_table = data_ID_rt %>% # Table with the relevant outcomes for task check
  group_by(Subject, `Vigilancia[Trial]`) %>% 
  summarise(Target.RT=mean(Target.RT)) %>%
  spread(`Vigilancia[Trial]`,Target.RT) %>% 
  rename_at(vars(DA:DP) ,function(x){paste0(x,"_RT")})
```

### Exploratory analysis of distractor position (same or opposite side as the target)

```{r}
x = data_ID_rt %>%
  group_by(Subject, LugarDistractortoTarget) %>% 
  summarise(Target.RT=mean(Target.RT)) %>%
  spread(LugarDistractortoTarget,Target.RT) %>% 
  rename_at(vars(opposite:same) ,function(x){paste0("Exploratory_D",x,"_RT")})
data_ID_table = bind_cols(data_ID_table,x[3:4])

rm(x)
```

### Compute ID analysis for RT (z-scores)

#### Interference of ID (RT)

```{r}
x = data_ID_table %>%
  mutate(ID_zRT = (DP_RT-DA_RT)/DA_RT)
data_processed=bind_cols(data_processed,x[6])
```

#### Exploratory: Interference of ID (RT) considering when distractor is presented in the same and the opposite side as the target location
```{r}
x = data_ID_table %>%
  mutate(Exploratory_ID_zRTsame = (Exploratory_Dsame_RT-DA_RT)/DA_RT) %>% 
  mutate(Exploratory_ID_zRTopposite = (Exploratory_Dopposite_RT-DA_RT)/DA_RT) 
data_processed=bind_cols(data_processed,x[6:7])

rm(x)
```

## ACC analysis (percentage errors) of ID trials

### Select appropriate trials (Only experimental blocks and ID trials) 

```{r}
data_ID_acc = data_raw %>% 
  filter(BlockList %in% experimentalblocks, `Vigilancia[Trial]` %in% IDtrials)
```

### Complete data table for ID analyses 

```{r}
x = data_ID_acc %>% # Table with the relevant outcomes for task check
  group_by(Subject, `Vigilancia[Trial]`) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%
  spread(`Vigilancia[Trial]`,Target.ACC) %>% 
  rename_at(vars(DA:DP) ,function(x){paste0(x,"_PercentageErrors")})
data_ID_table = bind_cols(data_ID_table,x[2:3])
```
### Exploratory analysis of distractor position (same or opposite side as the target)
```{r}
x = data_ID_acc %>% 
  group_by(Subject, LugarDistractortoTarget) %>% 
  summarise(Target.ACC=(1-mean(Target.ACC))*100) %>%
  spread(LugarDistractortoTarget,Target.ACC) %>% 
  rename_at(vars(opposite:same) ,function(x){paste0("Exploratory_D",x,"_PercentageErrors")})
data_ID_table = bind_cols(data_ID_table,x[3:4])

rm(x)
```

### Compute ID analysis for percentage errors (raw difference scores)

#### Errors interference from ID

```{r}
x = data_ID_table %>%
  mutate(ID_PercentageErrors = DP_PercentageErrors - DA_PercentageErrors)
data_processed=bind_cols(data_processed,x["ID_PercentageErrors"])
```

#### Exploratory: Errors interference from ID considering when distractor is presented in the same and the opposite side as the target location
```{r}
x = data_ID_table %>%
  mutate(Exploratory_PercentageErrorssame = Exploratory_Dsame_PercentageErrors - DA_PercentageErrors) %>% 
  mutate(Exploratory_PercentageErrorsopposite = Exploratory_Dopposite_PercentageErrors - DA_PercentageErrors)
data_processed=bind_cols(data_processed,x[c("Exploratory_PercentageErrorssame","Exploratory_PercentageErrorsopposite")])

rm(x)
```

```{r}
data_ID_table = data_ID_table %>% 
  filter(!Subject %in% c(outliers_performance,outliers_performance_IDtrials)) #Removing outliers from task analyses of ID trials
```

# Export tables

## Export tables of task analysis

```{r}
write.table(data_rt_table, "./Outputs/From_DataTaskTreatment/data_rt_table.csv", sep =",", row.names = FALSE)
write.table(data_acc_table, "./Outputs/From_DataTaskTreatment/data_acc_table.csv", sep =",", row.names = FALSE)
write.table(data_EV_table, "./Outputs/From_DataTaskTreatment/data_EV_table.csv", sep =",", row.names = FALSE)
write.table(data_AV_table, "./Outputs/From_DataTaskTreatment/data_AV_table.csv", sep =",", row.names = FALSE)
write.table(data_ID_table, "./Outputs/From_DataTaskTreatment/data_ID_table.csv", sep =",", row.names = FALSE)
```

## Export tables of task indexes 

Use this file in combination with self-report scores)

```{r}
write.table(data_processed, "./Outputs/From_DataTaskTreatment/data_processed.csv", sep =",", row.names = FALSE)
```
